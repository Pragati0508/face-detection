import os
from deepface import DeepFace
import cv2

# âœ… Optional: make TensorFlow logs quiet
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

# âœ… Emoji mapping for each emotion
emoji_map = {
    "happy": "ğŸ˜„",
    "sad": "ğŸ˜¢",
    "angry": "ğŸ˜¡",
    "surprise": "ğŸ˜²",
    "fear": "ğŸ˜¨",
    "neutral": "ğŸ˜",
    "disgust": "ğŸ¤¢"
}

print("ğŸ¥ Starting AI Emotion Detection... Press 'q' to quit.")

# âœ… Use CAP_DSHOW to fix Windows camera issue
cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)

# âœ… Check if camera opened properly
if not cap.isOpened():
    print("âŒ Camera not detected! Check your camera access or index.")
    exit()
else:
    print("âœ… Camera opened successfully!")

while True:
    ret, frame = cap.read()
    if not ret:
        
        print("âŒ Failed to capture frame.")
        break

    try:
        # âœ… Analyze current frame
        result = DeepFace.analyze(frame, actions=['emotion'], enforce_detection=False)

        # âœ… Handle both return types (list or dict)
        if isinstance(result, list):
            result = result[0]

        emotion = result['dominant_emotion']
        emoji = emoji_map.get(emotion.lower(), "")
        confidence = result['emotion'][emotion]

        # âœ… Display text + emoji on screen
        label = f"{emotion.capitalize()} {emoji}"
        cv2.putText(frame, label, (30, 60), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 3)
        cv2.putText(frame, f"Confidence: {confidence:.2f}", (30, 110),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)

    except Exception as e:
        # Handle occasional frame analysis errors gracefully
        print(f"âš ï¸ Frame skipped: {e}")

    # âœ… Show the video feed
    cv2.imshow("AI Emotion Detection ğŸ˜„", frame)

    # âœ… Exit when 'q' is pressed
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# âœ… Release camera and close window
cap.release()
cv2.destroyAllWindows()
